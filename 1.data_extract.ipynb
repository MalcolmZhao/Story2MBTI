{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/MVMR_BERT_tok.pkl\"\n",
    "# filename = \"BERT.tok.pkl\"\n",
    "with open(filename, \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/malcolmzhao/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/malcolmzhao/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to handle the pattern such as \"he ##llo\" to \"hello\n",
    "def decontract_text(string):\n",
    "    pattern = r'((?:\\w+ ##\\w+\\s)*)'\n",
    "    matches = re.findall(pattern, string)\n",
    "    for match in matches:\n",
    "        if len(match) > 0:\n",
    "            modified_string = re.sub(r\"[ #]\", \"\", match)\n",
    "            modified_string += \" \"\n",
    "            string = string.replace(match, modified_string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Tokenize the input text\n",
    "    text = decontract_text(text)\n",
    "    word_tokens = word_tokenize(text) # word_tokens will be a list of words in the input text.\n",
    "    # Remove stopwords and punctuations\n",
    "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words and word.isalnum()]\n",
    "    # Reconstruct the string\n",
    "    filtered_text_str = ' '.join(filtered_text)\n",
    "    return filtered_text_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_dict = {\n",
    "    \"i\": \"e\",\n",
    "    \"n\": \"s\",\n",
    "    \"f\": \"t\",\n",
    "    \"p\": \"j\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(idx, mbti_attr):\n",
    "    score = data[idx][mbti_attr.upper()]\n",
    "    if not (0 <= score <= 100):\n",
    "        score = 100 - data[idx][mbti_dict[mbti_attr].upper()]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400 "
     ]
    }
   ],
   "source": [
    "# create raw data with the below structure\n",
    "raw_data = pd.DataFrame({\n",
    "    \"id\": None,\n",
    "    \"person\": None,\n",
    "    \"category\": None,\n",
    "    \"i_score\": None,\n",
    "    \"n_score\": None,\n",
    "    \"f_score\": None,\n",
    "    \"p_score\": None,\n",
    "    \"dialog\": None\n",
    "    }, index = [0])\n",
    "for i in range(len(data)):\n",
    "    raw_data = raw_data.append({\n",
    "        \"id\": data[i][\"id\"],\n",
    "        \"person\": data[i][\"mbti_profile\"],\n",
    "        \"category\": data[i][\"subcategory\"],\n",
    "        \"i_score\": get_score(i, \"i\"),\n",
    "        \"n_score\": get_score(i, \"n\"),\n",
    "        \"f_score\": get_score(i, \"f\"),\n",
    "        \"p_score\": get_score(i, \"p\"),\n",
    "        \"dialog\": remove_stopwords(\"\".join(data[i][\"dialog_text\"]))\n",
    "    }, ignore_index = True)\n",
    "    # if i >= 2:\n",
    "    #     break\n",
    "    if i % 200 == 0:\n",
    "        print(\"\\r%d\"%i, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.dropna(subset = \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.reset_index(drop=True)\n",
    "drop_pool = (raw_data[[\"i_score\", \"n_score\", \"f_score\", \"p_score\"]].isna().sum(axis = 1) >= 3) # remove character with more than 3 channels are null\n",
    "raw_data = raw_data.loc[~drop_pool, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove characters with less than 80 words\n",
    "raw_data[\"information_length\"] = raw_data[\"dialog\"].apply(lambda x:len(x.split()))\n",
    "raw_data = raw_data.sort_values(by = \"information_length\", ascending = True)\n",
    "raw_data = raw_data.loc[raw_data[\"information_length\"] >= 80, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2360, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove charaters that do not have unique dialog\n",
    "raw_data = raw_data.drop_duplicates(subset = ['dialog'], keep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"i_score\", \"n_score\", \"f_score\", \"p_score\"]:\n",
    "    raw_data[col] = raw_data[col].fillna(raw_data[col].median()) # median fill na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2144, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.to_excel(\"data/MVMR_BERT_tok.xlsx\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
